{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e00f38-820c-4ebb-a105-a73e1deac12b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/speed-scratch/l_hongwu/Jupyter/jupyter-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea141c2c-865d-4606-ba43-10aa9dcb6822",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "eclipse_url = \"https://github.com/logpai/bughub/raw/refs/heads/master/EclipsePlatform/\"\n",
    "firefox_url = \"https://raw.githubusercontent.com/logpai/bughub/refs/heads/master/Firefox/\"\n",
    "jdt_url = \"https://raw.githubusercontent.com/logpai/bughub/refs/heads/master/JDT/\"\n",
    "mozilla_url = \"https://github.com/logpai/bughub/raw/refs/heads/master/MozillaCore/\"\n",
    "thunderbird_url = \"https://raw.githubusercontent.com/logpai/bughub/refs/heads/master/Thunderbird/\"\n",
    "\n",
    "def load_from_bughub(url, bugs):\n",
    "    dataset = load_dataset(\"csv\", data_files = url + bugs)\n",
    "    train = load_dataset(\"csv\", data_files = url + \"train.csv\")\n",
    "    test = load_dataset(\"csv\", data_files = url + \"test.csv\")\n",
    "    return dataset, train, test\n",
    "\n",
    "\n",
    "eclipse_dataset, eclipse_train, eclipse_test = load_from_bughub(eclipse_url, \"eclipse_platform.zip\")\n",
    "firefox_dataset, firefox_train, firefox_test = load_from_bughub(firefox_url, \"mozilla_firefox.zip\")\n",
    "jdt_dataset, jdt_train, jdt_test = load_from_bughub(jdt_url,\"eclipse_jdt.csv\")\n",
    "mozilla_dataset, mozilla_train, mozilla_test = load_from_bughub(mozilla_url, \"mozilla_core.zip\")\n",
    "thunderbird_dataset, thunderbird_train, thunderbird_test = load_from_bughub(thunderbird_url, \"mozilla_thunderbird.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ac06aa-97f9-40c7-b833-061db3b4eb6c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def create_datasets(dataset, train, test):\n",
    "    dataset_df = dataset['train'].to_pandas()\n",
    "    train_df = train['train'].to_pandas()\n",
    "    test_df = test['train'].to_pandas()    \n",
    "    train_data = train_df.merge(dataset_df, on=\"Issue_id\", how=\"left\")\n",
    "    train_data = pd.DataFrame(train_data).values.tolist()\n",
    "    test_data = test_df.merge(dataset_df, on=\"Issue_id\", how=\"left\")\n",
    "    test_data = pd.DataFrame(test_data).values.tolist()\n",
    "    issue_dict = {issue[\"Issue_id\"]: issue for issue in dataset[\"train\"].to_list()}\n",
    "    return train_data, test_data, issue_dict\n",
    "\n",
    "eclipse_train, eclipse_test, eclipse_dict = create_datasets(eclipse_dataset, eclipse_train, eclipse_test)\n",
    "firefox_train, firefox_test, firefox_dict = create_datasets(firefox_dataset, firefox_train, firefox_test)\n",
    "jdt_train, jdt_test, jdt_dict = create_datasets(jdt_dataset, jdt_train, jdt_test)\n",
    "mozilla_train, mozilla_test, mozilla_dict = create_datasets(mozilla_dataset, mozilla_train, mozilla_test)\n",
    "thunderbird_train, thunderbird_test, thunderbird_dict = create_datasets(thunderbird_dataset, thunderbird_train, thunderbird_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8caa36f5-bcda-4a7a-b125-16982ac89f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 保存 eclipse 数据集\n",
    "pd.DataFrame(eclipse_train).to_csv('eclipse_train.csv', index=False)\n",
    "pd.DataFrame(eclipse_test).to_csv('eclipse_test.csv', index=False)\n",
    "pd.DataFrame.from_dict(eclipse_dict, orient='index').to_csv('eclipse_dict.csv', index=False)\n",
    "\n",
    "# 保存 firefox 数据集\n",
    "pd.DataFrame(firefox_train).to_csv('firefox_train.csv', index=False)\n",
    "pd.DataFrame(firefox_test).to_csv('firefox_test.csv', index=False)\n",
    "pd.DataFrame.from_dict(firefox_dict, orient='index').to_csv('firefox_dict.csv', index=False)\n",
    "\n",
    "# 保存 jdt 数据集\n",
    "pd.DataFrame(jdt_train).to_csv('jdt_train.csv', index=False)\n",
    "pd.DataFrame(jdt_test).to_csv('jdt_test.csv', index=False)\n",
    "pd.DataFrame.from_dict(jdt_dict, orient='index').to_csv('jdt_dict.csv', index=False)\n",
    "\n",
    "# 保存 mozilla 数据集\n",
    "pd.DataFrame(mozilla_train).to_csv('mozilla_train.csv', index=False)\n",
    "pd.DataFrame(mozilla_test).to_csv('mozilla_test.csv', index=False)\n",
    "pd.DataFrame.from_dict(mozilla_dict, orient='index').to_csv('mozilla_dict.csv', index=False)\n",
    "\n",
    "# 保存 thunderbird 数据集\n",
    "pd.DataFrame(thunderbird_train).to_csv('thunderbird_train.csv', index=False)\n",
    "pd.DataFrame(thunderbird_test).to_csv('thunderbird_test.csv', index=False)\n",
    "pd.DataFrame.from_dict(thunderbird_dict, orient='index').to_csv('thunderbird_dict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb7913b-99bc-4972-8b28-c533d4900b37",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "\n",
    "SEED = 69  # Change this number for different results\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)  # Python's random module\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (if available)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic optimizations\n",
    "\n",
    "\n",
    "def create_pairs(dataset, issue_dict):\n",
    "    pairs = []\n",
    "    for entry in dataset:\n",
    "        issue_id = entry[0] \n",
    "        duplicates = entry[1]  # List of duplicate issue IDs\n",
    "        \n",
    "        if duplicates:\n",
    "            duplicates = entry[1].split(\";\")\n",
    "            for dup_id in duplicates:\n",
    "                if int(dup_id) in issue_dict:\n",
    "                    dup_id = int(dup_id)\n",
    "                    bug_1 = (issue_dict[issue_id][\"Component\"] or \"\") + \" \" + (issue_dict[issue_id][\"Title\"] or \"\") + \" \" + (issue_dict[issue_id][\"Description\"] or \"\")\n",
    "                    bug_2 = (issue_dict[dup_id][\"Component\"] or \"\") + \" \" + (issue_dict[dup_id][\"Title\"] or \"\") + \" \" + (issue_dict[dup_id][\"Description\"] or \"\")\n",
    "                    pairs.append(InputExample(\n",
    "                        texts = [bug_1, bug_2],\n",
    "                        label = 1\n",
    "                    ))\n",
    "\n",
    "            # Create negative samples (random non-duplicate issues)\n",
    "            for _ in range(len(duplicates)):  # Create equal number of negative pairs\n",
    "                random_id = random.choice(list(issue_dict.keys()))\n",
    "                if str(random_id) not in duplicates and random_id != issue_id:\n",
    "                    bug_1 = (issue_dict[issue_id][\"Component\"] or \"\") + \" \" + (issue_dict[issue_id][\"Title\"] or \"\") + \" \" + (issue_dict[issue_id][\"Description\"] or \"\")\n",
    "                    bug_2 = (issue_dict[random_id][\"Component\"] or \"\") + \" \" + (issue_dict[random_id][\"Title\"] or \"\") + \" \" + (issue_dict[random_id][\"Description\"] or \"\")\n",
    "                    pairs.append(InputExample(\n",
    "                        texts = [bug_1, bug_2],\n",
    "                        label = 0\n",
    "                    ))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "datasets = [\n",
    "    (\"eclipse_train\", eclipse_train, eclipse_dict),\n",
    "    (\"eclipse_test\", eclipse_test, eclipse_dict),\n",
    "    (\"firefox_train\", firefox_train, firefox_dict),\n",
    "    (\"firefox_test\", firefox_test, firefox_dict),\n",
    "    (\"jdt_train\", jdt_train, jdt_dict),\n",
    "    (\"jdt_test\", jdt_test, jdt_dict),\n",
    "    (\"mozilla_train\", mozilla_train, mozilla_dict),\n",
    "    (\"mozilla_test\", mozilla_test, mozilla_dict),\n",
    "    (\"thunderbird_train\", thunderbird_train, thunderbird_dict),\n",
    "    (\"thunderbird_test\", thunderbird_test, thunderbird_dict),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "def process_dataset(name, data, dictionary):\n",
    "    return name, create_pairs(data, dictionary)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(process_dataset, name, data, dictionary): name for name, data, dictionary in datasets}\n",
    "    \n",
    "    for future in futures:\n",
    "        name, result = future.result()\n",
    "        results[name] = result\n",
    "\n",
    "# Assign results to variables dynamically\n",
    "eclipse_train_samples = results[\"eclipse_train\"]\n",
    "eclipse_test_samples = results[\"eclipse_test\"]\n",
    "firefox_train_samples = results[\"firefox_train\"]\n",
    "firefox_test_samples = results[\"firefox_test\"]\n",
    "jdt_train_samples = results[\"jdt_train\"]\n",
    "jdt_test_samples = results[\"jdt_test\"]\n",
    "mozilla_train_samples = results[\"mozilla_train\"]\n",
    "mozilla_test_samples = results[\"mozilla_test\"]\n",
    "thunderbird_train_samples = results[\"thunderbird_train\"]\n",
    "thunderbird_test_samples = results[\"thunderbird_test\"]\n",
    "\n",
    "train_samples = eclipse_train_samples + firefox_train_samples + jdt_train_samples + mozilla_train_samples + thunderbird_train_samples\n",
    "test_samples =  eclipse_test_samples + firefox_test_samples + jdt_test_samples + mozilla_test_samples + thunderbird_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d3a922-89a3-43a1-b3a9-8393d2413c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "\n",
    "SEED = 69  # Change this number for different results\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)  # Python's random module\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (if available)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic optimizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807cf2e2-0b74-4aea-a9d4-c73402cf95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_to_dataframe(pairs):\n",
    "    data = []\n",
    "    for pair in pairs:\n",
    "        # pair.texts 是一个包含两个文本的列表，pair.label 是标签\n",
    "        data.append({\n",
    "            \"text1\": pair.texts[0],\n",
    "            \"text2\": pair.texts[1],\n",
    "            \"label\": pair.label\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# 转换训练和测试数据为 DataFrame\n",
    "df_train = pairs_to_dataframe(train_samples)\n",
    "df_test = pairs_to_dataframe(test_samples)\n",
    "\n",
    "# 保存为 CSV 文件到当前文件夹\n",
    "df_train.to_csv(\"train_pairs.csv\", index=False, encoding=\"utf-8\")\n",
    "df_test.to_csv(\"test_pairs.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc41acdc-d960-47b6-9357-f0016723de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file, encoding=\"utf-8\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        return InputExample(texts=[row[\"text1\"], row[\"text2\"]], label=float(row[\"label\"]))\n",
    "\n",
    "# 加载 CSV 数据集\n",
    "train_dataset = PairDataset(\"train_pairs.csv\")\n",
    "test_dataset = PairDataset(\"test_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61afb009-4b7c-4193-95da-f823f58ed968",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22948' max='22948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22948/22948 2:17:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.028100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = torch.nn.DataParallel(model)  # multiple GPU\n",
    "model.to(device)\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128, num_workers=3, pin_memory=True, prefetch_factor=2, worker_init_fn=lambda _: set_seed(SEED))\n",
    "\n",
    "num_epochs = 2\n",
    "warmup_steps = int(0.05 * len(train_dataloader) * num_epochs)\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    use_amp=True,\n",
    "    show_progress_bar=True,\n",
    "    optimizer_params={\"lr\": 2e-5, \"weight_decay\": 1.00}  # Adjust these values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4d814e0-293f-47f8-bd5d-53d0bf5128bc",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8861\n",
      "Recall: 0.5748\n",
      "F1-score: 0.6972\n",
      "F2-score: 0.6182\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "import torch\n",
    "\n",
    "# Function to evaluate test samples\n",
    "def evaluate_model(model, test_samples):\n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    total = len(test_samples)\n",
    "\n",
    "    for sample in test_dataset:\n",
    "        text1, text2 = sample.texts\n",
    "        label = sample.label  # Ground truth (1 for duplicate, 0 for non-duplicate)\n",
    "\n",
    "        # Compute embeddings\n",
    "        emb1 = model.encode(text1, convert_to_tensor=True)\n",
    "        emb2 = model.encode(text2, convert_to_tensor=True)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarity = util.pytorch_cos_sim(emb1, emb2).item()\n",
    "\n",
    "        # Threshold (adjust based on your dataset)\n",
    "        prediction = 1 if similarity > 0.5 else 0\n",
    "\n",
    "        # Compare with ground truth\n",
    "        # Count TP, FP, FN\n",
    "        if prediction == 1 and label == 1:\n",
    "            TP += 1  # True Positive\n",
    "        elif prediction == 1 and label == 0:\n",
    "            FP += 1  # False Positive\n",
    "        elif prediction == 0 and label == 1:\n",
    "            FN += 1  # False Negative\n",
    "\n",
    "\n",
    "    # Compute metrics\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    f2_score = (5 * precision * recall) / ((4 * precision) + recall) if (precision + recall) > 0 else 0 \n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1_score:.4f}\")\n",
    "    print(f\"F2-score: {f2_score:.4f}\") \n",
    "\n",
    "# Run evaluation\n",
    "evaluate_model(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c29563-417d-49ae-9094-ced35b653372",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Threshold: 0.0606\n",
      "Precision: 0.7669\n",
      "Recall: 0.7584\n",
      "F1-score: 0.7626\n",
      "F2-score: 0.7601\n",
      "Accuracy: 0.7637\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "def evaluate_model(model, test_samples):\n",
    "    \n",
    "    all_similarities = []\n",
    "    all_labels = []\n",
    "    \n",
    "   \n",
    "    for sample in test_samples:\n",
    "        text1, text2 = sample.texts\n",
    "        label = sample.label\n",
    "        \n",
    "       \n",
    "        emb1 = model.encode(text1, convert_to_tensor=True)\n",
    "        emb2 = model.encode(text2, convert_to_tensor=True)\n",
    "        \n",
    "       \n",
    "        similarity = util.pytorch_cos_sim(emb1, emb2).item()\n",
    "        \n",
    "        all_similarities.append(similarity)\n",
    "        all_labels.append(label)\n",
    "\n",
    "    \n",
    "    similarities = np.array(all_similarities)\n",
    "    labels = np.array(all_labels)\n",
    "\n",
    "    \n",
    "    # 1. ROC and AUC\n",
    "    fpr, tpr, thresholds_roc = roc_curve(labels, similarities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Precision-recall curve\n",
    "    precision, recall, thresholds_pr = precision_recall_curve(labels, similarities)\n",
    "    avg_precision = auc(recall, precision)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'AP={avg_precision:.2f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig('pr_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Threshold evaluation\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    f1_scores = []\n",
    "    f2_scores = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        preds = (similarities > thresh).astype(int)\n",
    "        tp = np.sum((preds == 1) & (labels == 1))\n",
    "        fp = np.sum((preds == 1) & (labels == 0))\n",
    "        fn = np.sum((preds == 0) & (labels == 1))\n",
    "        tn = np.sum((preds == 0) & (labels == 0))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f2 = (5 * precision * recall) / (4 * precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0 else 0\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "        f2_scores.append(f2)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, f1_scores, label='F1 Score')\n",
    "    plt.plot(thresholds, f2_scores, label='F2 Score')\n",
    "    plt.plot(thresholds, precisions, label='Precision')\n",
    "    plt.plot(thresholds, recalls, label='Recall')\n",
    "    plt.plot(thresholds, accuracies, label='Accuracy')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Metrics vs Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('metrics_vs_threshold.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 4. Confusion matrix\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_thresh = thresholds[best_idx]\n",
    "    preds = (similarities > best_thresh).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Duplicate', 'Duplicate'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix (Threshold={best_thresh:.2f})')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 5. Similarity distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(similarities[labels == 1], bins=30, alpha=0.5, label='Duplicates', color='g')\n",
    "    plt.hist(similarities[labels == 0], bins=30, alpha=0.5, label='Non-Duplicates', color='r')\n",
    "    plt.xlabel('Similarity Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Similarity Score Distribution')\n",
    "    plt.legend()\n",
    "    plt.savefig('similarity_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\nBest Threshold: {best_thresh:.4f}\")\n",
    "    print(f\"Precision: {precisions[best_idx]:.4f}\")\n",
    "    print(f\"Recall: {recalls[best_idx]:.4f}\")\n",
    "    print(f\"F1-score: {f1_scores[best_idx]:.4f}\")\n",
    "    print(f\"F2-score: {f2_scores[best_idx]:.4f}\")\n",
    "    print(f\"Accuracy: {accuracies[best_idx]:.4f}\")\n",
    "\n",
    "evaluate_model(model, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80759489-47fc-4342-b5f7-07e3df2e6d04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupyterlab": {
   "notebooks": {
    "version_major": 6,
    "version_minor": 4
   }
  },
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "singlestore_cell_default_language": "python",
  "singlestore_connection": {
   "connectionID": "",
   "defaultDatabase": ""
  },
  "singlestore_row_limit": 300
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
